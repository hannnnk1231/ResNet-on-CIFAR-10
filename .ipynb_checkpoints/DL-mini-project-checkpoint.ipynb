{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PXDEvoP8Y_ST"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMxW9mP6nxEs",
    "outputId": "0de71445-c0af-4cae-cfaf-0d64705e69aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 16 04:51:55 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   74C    P8    12W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUbFbRDuZgZf"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3s4QzGbaaNbU",
    "outputId": "d7640f63-2ab7-4de9-b281-1116373728de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "ROOT = '.data'\n",
    "train_data = datasets.CIFAR10(root = ROOT, train = True, download = True)\n",
    "\n",
    "# Compute means and standard deviations along the R,G,B channel\n",
    "\n",
    "means = train_data.data.mean(axis = (0,1,2)) / 255\n",
    "stds = train_data.data.std(axis = (0,1,2)) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O4yR6-LFaIvM"
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                           transforms.RandomRotation(5),\n",
    "                           transforms.RandomHorizontalFlip(0.5),\n",
    "                           transforms.RandomCrop(32, padding = 2),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = means, std = stds)\n",
    "                       ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = means, std = stds)\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWlHIjAIZkiZ",
    "outputId": "efab5777-3d83-40eb-e95c-9b2d5cba9006"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10(ROOT, \n",
    "                              train = True, \n",
    "                              download = True, \n",
    "                              transform = train_transforms)\n",
    "\n",
    "test_data = datasets.CIFAR10(ROOT, \n",
    "                             train = False, \n",
    "                             download = True, \n",
    "                             transform = test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z_nGIR5ebJ9e"
   },
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(train_data, [n_train_examples, n_valid_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZbjxV1RlaaeI"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "train_iterator = DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True) \n",
    "\n",
    "valid_iterator = DataLoader(valid_data, batch_size = BATCH_SIZE, shuffle = False) \n",
    "\n",
    "test_iterator = DataLoader(test_data, batch_size = BATCH_SIZE, shuffle = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWIkMT6RbVWt"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tNpLNkgJbSVT"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d( in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        block = BasicBlock\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpte7ypce2aW",
    "outputId": "8f66f210-5b2b-4891-ecbb-55d2cecc599e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-14           [-1, 64, 32, 32]             128\n",
      "           Conv2d-15           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-17           [-1, 64, 32, 32]               0\n",
      "           Conv2d-18          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-19          [-1, 128, 16, 16]             256\n",
      "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
      "           Conv2d-22          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
      "           Conv2d-25          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-26          [-1, 128, 16, 16]             256\n",
      "           Conv2d-27          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-28          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-29          [-1, 128, 16, 16]               0\n",
      "           Conv2d-30          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-31          [-1, 128, 16, 16]             256\n",
      "           Conv2d-32          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-33          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-34          [-1, 128, 16, 16]               0\n",
      "           Conv2d-35            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 8, 8]             512\n",
      "           Conv2d-37            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-38            [-1, 256, 8, 8]             512\n",
      "           Conv2d-39            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-40            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-41            [-1, 256, 8, 8]               0\n",
      "           Conv2d-42            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-43            [-1, 256, 8, 8]             512\n",
      "           Conv2d-44            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-46            [-1, 256, 8, 8]               0\n",
      "           Conv2d-47            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 8, 8]             512\n",
      "           Conv2d-49            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-50            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-51            [-1, 256, 8, 8]               0\n",
      "           Linear-52                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 4,335,434\n",
      "Trainable params: 4,335,434\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 14.88\n",
      "Params size (MB): 16.54\n",
      "Estimated Total Size (MB): 31.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "#model = ResNet([2, 2, 2]).to(device)\n",
    "model = ResNet([3, 3, 3]).to(device)\n",
    "\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nHgAnLIQe4q5"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y46vNlbQq3xb"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "i6ZskXEsqxZG"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (x, y) in iterator:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WnypBZhNA26r"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5RMycfahbyk",
    "outputId": "6a6cf419-02ef-4f01-e6f6-449d58649e04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  1\n",
      "Train loss:  1.6476190638813106\n",
      "Train acc:  0.3943164062432267\n",
      "Validation loss:  1.3515185296535492\n",
      "Validation acc:  0.5081571698188782\n",
      "EPOCH:  2\n",
      "Train loss:  1.2557860348712315\n",
      "Train acc:  0.5500665838745508\n",
      "Validation loss:  1.1695684611797332\n",
      "Validation acc:  0.5803998172283172\n",
      "EPOCH:  3\n",
      "Train loss:  1.0863372514193708\n",
      "Train acc:  0.6114346591586416\n",
      "Validation loss:  1.029601600766182\n",
      "Validation acc:  0.6292394310235977\n",
      "EPOCH:  4\n",
      "Train loss:  0.9579682827673175\n",
      "Train acc:  0.6596342328597199\n",
      "Validation loss:  0.9926017612218857\n",
      "Validation acc:  0.6448874086141586\n",
      "EPOCH:  5\n",
      "Train loss:  0.8575609939342196\n",
      "Train acc:  0.6971129260279916\n",
      "Validation loss:  0.8856010198593139\n",
      "Validation acc:  0.6912454038858413\n",
      "EPOCH:  6\n",
      "Train loss:  0.7800793126225471\n",
      "Train acc:  0.7256427556276321\n",
      "Validation loss:  0.8387568056583404\n",
      "Validation acc:  0.7063304215669632\n",
      "EPOCH:  7\n",
      "Train loss:  0.7187297733669932\n",
      "Train acc:  0.7475941049104388\n",
      "Validation loss:  0.8241463392972946\n",
      "Validation acc:  0.7219554215669632\n",
      "EPOCH:  8\n",
      "Train loss:  0.6597110107541084\n",
      "Train acc:  0.7690642753785307\n",
      "Validation loss:  0.7307987093925477\n",
      "Validation acc:  0.7469439327716827\n",
      "EPOCH:  9\n",
      "Train loss:  0.6185728941451419\n",
      "Train acc:  0.7826544744047251\n",
      "Validation loss:  0.7865011721849442\n",
      "Validation acc:  0.7364200383424759\n",
      "EPOCH:  10\n",
      "Train loss:  0.5804222260009159\n",
      "Train acc:  0.7958735793151639\n",
      "Validation loss:  0.6580444619059562\n",
      "Validation acc:  0.7675666362047195\n",
      "EPOCH:  11\n",
      "Train loss:  0.5441820149055936\n",
      "Train acc:  0.8087029474025423\n",
      "Validation loss:  0.6046700134873391\n",
      "Validation acc:  0.7875804215669632\n",
      "EPOCH:  12\n",
      "Train loss:  0.5146065833555027\n",
      "Train acc:  0.819114879112352\n",
      "Validation loss:  0.6334451228380203\n",
      "Validation acc:  0.7870404422283173\n",
      "EPOCH:  13\n",
      "Train loss:  0.49418365684422577\n",
      "Train acc:  0.827537286687981\n",
      "Validation loss:  0.5856643036007881\n",
      "Validation acc:  0.7963924646377564\n",
      "EPOCH:  14\n",
      "Train loss:  0.46435887163335626\n",
      "Train acc:  0.8382874642583457\n",
      "Validation loss:  0.59413333684206\n",
      "Validation acc:  0.7925551474094391\n",
      "EPOCH:  15\n",
      "Train loss:  0.4411910518326543\n",
      "Train acc:  0.8457785865122621\n",
      "Validation loss:  0.5616342812776566\n",
      "Validation acc:  0.804296875\n",
      "EPOCH:  16\n",
      "Train loss:  0.4206888350573453\n",
      "Train acc:  0.8536931818181818\n",
      "Validation loss:  0.5218810066580772\n",
      "Validation acc:  0.8195886939764023\n",
      "EPOCH:  17\n",
      "Train loss:  0.4021254758435217\n",
      "Train acc:  0.8603648790581659\n",
      "Validation loss:  0.5728354841470719\n",
      "Validation acc:  0.8006663590669632\n",
      "EPOCH:  18\n",
      "Train loss:  0.39005120911381463\n",
      "Train acc:  0.8633016689934514\n",
      "Validation loss:  0.587896192073822\n",
      "Validation acc:  0.8018841922283173\n",
      "EPOCH:  19\n",
      "Train loss:  0.3710275190797719\n",
      "Train acc:  0.8699556108225476\n",
      "Validation loss:  0.5158654153347015\n",
      "Validation acc:  0.8241038590669632\n",
      "EPOCH:  20\n",
      "Train loss:  0.35819431563669984\n",
      "Train acc:  0.8756969103758986\n",
      "Validation loss:  0.5165219619870186\n",
      "Validation acc:  0.8225183814764023\n",
      "EPOCH:  21\n",
      "Train loss:  0.34040083397518506\n",
      "Train acc:  0.8809392753649842\n",
      "Validation loss:  0.5349811896681785\n",
      "Validation acc:  0.8172219663858413\n",
      "EPOCH:  22\n",
      "Train loss:  0.32561885709451005\n",
      "Train acc:  0.8864115764471617\n",
      "Validation loss:  0.5047033816576004\n",
      "Validation acc:  0.8301585465669632\n",
      "EPOCH:  23\n",
      "Train loss:  0.31049929711629043\n",
      "Train acc:  0.8921244672753594\n",
      "Validation loss:  0.5389883682131767\n",
      "Validation acc:  0.8187614887952804\n",
      "EPOCH:  24\n",
      "Train loss:  0.29815014671872964\n",
      "Train acc:  0.8957004614851691\n",
      "Validation loss:  0.5084808871150017\n",
      "Validation acc:  0.830296415090561\n",
      "EPOCH:  25\n",
      "Train loss:  0.2914129744537852\n",
      "Train acc:  0.8989666192369028\n",
      "Validation loss:  0.5320170819759369\n",
      "Validation acc:  0.8262752771377564\n",
      "EPOCH:  26\n",
      "Train loss:  0.2769518308341503\n",
      "Train acc:  0.904052734375\n",
      "Validation loss:  0.5149848505854606\n",
      "Validation acc:  0.8233455896377564\n",
      "EPOCH:  27\n",
      "Train loss:  0.2641811352223158\n",
      "Train acc:  0.9082768109034408\n",
      "Validation loss:  0.49533013105392454\n",
      "Validation acc:  0.8333524823188782\n",
      "EPOCH:  28\n",
      "Train loss:  0.25987794174050743\n",
      "Train acc:  0.9092080965638161\n",
      "Validation loss:  0.5218783840537071\n",
      "Validation acc:  0.8304227948188782\n",
      "EPOCH:  29\n",
      "Train loss:  0.24760960127142342\n",
      "Train acc:  0.91314186765389\n",
      "Validation loss:  0.514122673869133\n",
      "Validation acc:  0.8345473349094391\n",
      "EPOCH:  30\n",
      "Train loss:  0.23936866054480727\n",
      "Train acc:  0.916748046875\n",
      "Validation loss:  0.5186610877513885\n",
      "Validation acc:  0.8332605689764023\n",
      "EPOCH:  31\n",
      "Train loss:  0.22659666853194887\n",
      "Train acc:  0.9212171520021829\n",
      "Validation loss:  0.4752111315727234\n",
      "Validation acc:  0.8464728862047195\n",
      "EPOCH:  32\n",
      "Train loss:  0.22354570488360795\n",
      "Train acc:  0.921648614785888\n",
      "Validation loss:  0.43930953592061994\n",
      "Validation acc:  0.8552389711141586\n",
      "EPOCH:  33\n",
      "Train loss:  0.2165229699828408\n",
      "Train acc:  0.9245019531385466\n",
      "Validation loss:  0.520381036400795\n",
      "Validation acc:  0.8366038590669632\n",
      "EPOCH:  34\n",
      "Train loss:  0.20258681459183042\n",
      "Train acc:  0.9292036576027219\n",
      "Validation loss:  0.4568242639303207\n",
      "Validation acc:  0.8520335465669632\n",
      "EPOCH:  35\n",
      "Train loss:  0.19822339556941931\n",
      "Train acc:  0.9304723011499102\n",
      "Validation loss:  0.5411603018641472\n",
      "Validation acc:  0.8322840064764023\n",
      "EPOCH:  36\n",
      "Train loss:  0.19135006974366578\n",
      "Train acc:  0.9330735084685412\n",
      "Validation loss:  0.6020018368959427\n",
      "Validation acc:  0.8186121314764023\n",
      "EPOCH:  37\n",
      "Train loss:  0.1788967295803807\n",
      "Train acc:  0.9376695667478171\n",
      "Validation loss:  0.4580471083521843\n",
      "Validation acc:  0.8563763797283173\n",
      "EPOCH:  38\n",
      "Train loss:  0.1741337368095463\n",
      "Train acc:  0.9389035864309832\n",
      "Validation loss:  0.5364829272031784\n",
      "Validation acc:  0.8399126827716827\n",
      "EPOCH:  39\n",
      "Train loss:  0.1705654221586883\n",
      "Train acc:  0.9415882456709038\n",
      "Validation loss:  0.45154882222414017\n",
      "Validation acc:  0.8522518396377563\n",
      "EPOCH:  40\n",
      "Train loss:  0.16141318034550006\n",
      "Train acc:  0.9435387074270032\n",
      "Validation loss:  0.4515348717570305\n",
      "Validation acc:  0.8605583637952805\n",
      "EPOCH:  41\n",
      "Train loss:  0.1550380717539652\n",
      "Train acc:  0.9452920810065486\n",
      "Validation loss:  0.4160815700888634\n",
      "Validation acc:  0.8690602034330368\n",
      "EPOCH:  42\n",
      "Train loss:  0.1480669705197215\n",
      "Train acc:  0.9482111148536205\n",
      "Validation loss:  0.465138903260231\n",
      "Validation acc:  0.8543543189764022\n",
      "EPOCH:  43\n",
      "Train loss:  0.1399652189998464\n",
      "Train acc:  0.9519566761499102\n",
      "Validation loss:  0.508665132522583\n",
      "Validation acc:  0.8530330896377564\n",
      "EPOCH:  44\n",
      "Train loss:  0.13537876879457722\n",
      "Train acc:  0.9532688209279017\n",
      "Validation loss:  0.5115970894694328\n",
      "Validation acc:  0.8486672788858414\n",
      "EPOCH:  45\n",
      "Train loss:  0.13274114532396197\n",
      "Train acc:  0.9540456320074472\n",
      "Validation loss:  0.4503850191831589\n",
      "Validation acc:  0.8688648909330368\n",
      "EPOCH:  46\n",
      "Train loss:  0.12735103447498244\n",
      "Train acc:  0.9559765624051745\n",
      "Validation loss:  0.4838693603873253\n",
      "Validation acc:  0.8538143396377563\n",
      "EPOCH:  47\n",
      "Train loss:  0.11994968128221278\n",
      "Train acc:  0.9583327414637263\n",
      "Validation loss:  0.505882841348648\n",
      "Validation acc:  0.8484489887952804\n",
      "EPOCH:  48\n",
      "Train loss:  0.1166549734136259\n",
      "Train acc:  0.9591912285170772\n",
      "Validation loss:  0.4619169607758522\n",
      "Validation acc:  0.8617532163858413\n",
      "EPOCH:  49\n",
      "Train loss:  0.1123640148434788\n",
      "Train acc:  0.9619655538011681\n",
      "Validation loss:  0.45409413427114487\n",
      "Validation acc:  0.8642463237047195\n",
      "EPOCH:  50\n",
      "Train loss:  0.11149279280057685\n",
      "Train acc:  0.9610298292880709\n",
      "Validation loss:  0.46757842451334\n",
      "Validation acc:  0.8609949439764023\n",
      "EPOCH:  51\n",
      "Train loss:  0.10295890186997977\n",
      "Train acc:  0.9640012427487157\n",
      "Validation loss:  0.4548884563148022\n",
      "Validation acc:  0.8649586409330368\n",
      "EPOCH:  52\n",
      "Train loss:  0.10216194571165199\n",
      "Train acc:  0.9653107242828066\n",
      "Validation loss:  0.5024204432964325\n",
      "Validation acc:  0.8572380512952804\n",
      "EPOCH:  53\n",
      "Train loss:  0.09396083003164014\n",
      "Train acc:  0.9677459160712633\n",
      "Validation loss:  0.4650386571884155\n",
      "Validation acc:  0.8691521137952805\n",
      "EPOCH:  54\n",
      "Train loss:  0.08915067364631052\n",
      "Train acc:  0.9700887782329862\n",
      "Validation loss:  0.466987369954586\n",
      "Validation acc:  0.8657858461141587\n",
      "EPOCH:  55\n",
      "Train loss:  0.08915729875761\n",
      "Train acc:  0.9689311076971617\n",
      "Validation loss:  0.48214108794927596\n",
      "Validation acc:  0.8627527564764023\n",
      "EPOCH:  56\n",
      "Train loss:  0.0812919769986448\n",
      "Train acc:  0.9719531248238954\n",
      "Validation loss:  0.549440574645996\n",
      "Validation acc:  0.8529641538858413\n",
      "EPOCH:  57\n",
      "Train loss:  0.08591949971477417\n",
      "Train acc:  0.9702219458466227\n",
      "Validation loss:  0.48319787681102755\n",
      "Validation acc:  0.8676930159330368\n",
      "EPOCH:  58\n",
      "Train loss:  0.07903497793119062\n",
      "Train acc:  0.9739470878107981\n",
      "Validation loss:  0.5352621495723724\n",
      "Validation acc:  0.8525275737047195\n",
      "EPOCH:  59\n",
      "Train loss:  0.07395329022653062\n",
      "Train acc:  0.975609019737352\n",
      "Validation loss:  0.45814834386110304\n",
      "Validation acc:  0.8675436586141586\n",
      "EPOCH:  60\n",
      "Train loss:  0.07125311336395415\n",
      "Train acc:  0.9763094813308932\n",
      "Validation loss:  0.5049868777394295\n",
      "Validation acc:  0.8660041362047195\n",
      "EPOCH:  61\n",
      "Train loss:  0.06678731722587888\n",
      "Train acc:  0.9784339486875318\n",
      "Validation loss:  0.502842116355896\n",
      "Validation acc:  0.8674977034330368\n",
      "EPOCH:  62\n",
      "Train loss:  0.06799527816474438\n",
      "Train acc:  0.9765669388527219\n",
      "Validation loss:  0.47358656376600267\n",
      "Validation acc:  0.8664407163858414\n",
      "EPOCH:  63\n",
      "Train loss:  0.0648977535628629\n",
      "Train acc:  0.9783194244585254\n",
      "Validation loss:  0.47809118777513504\n",
      "Validation acc:  0.8706227034330368\n",
      "EPOCH:  64\n",
      "Train loss:  0.06183128869584338\n",
      "Train acc:  0.9800727980380709\n",
      "Validation loss:  0.4723067969083786\n",
      "Validation acc:  0.8621897965669632\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "# Fill training code here\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "  valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "  train_loss_list.append(train_loss)\n",
    "  train_acc_list.append(train_acc)\n",
    "  val_loss_list.append(valid_loss)\n",
    "  val_acc_list.append(valid_acc)\n",
    "\n",
    "  if valid_loss < best_valid_loss:\n",
    "    best_valid_loss = valid_loss\n",
    "    torch.save(model.state_dict(), 'best.pt')\n",
    "  print(\"EPOCH: \", epoch)\n",
    "  print(\"Train loss: \", train_loss)\n",
    "  print(\"Train acc: \", train_acc)\n",
    "  print(\"Validation loss: \", valid_loss)\n",
    "  print(\"Validation acc: \", valid_acc)\n",
    "\n",
    "  scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4Ki2NUDBRrT"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "print(\"Test loss: \", test_loss)\n",
    "print(\"Test acc: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DR2zlCRMf7Mo"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = range(1, 80+1)\n",
    "plt.plot(epochs, train_acc_list, 'bo', label=\"training acc\")\n",
    "plt.plot(epochs, val_acc_list, 'b', label=\"validation acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4nLgLwDghjt"
   },
   "outputs": [],
   "source": [
    "epochs = range(1, 80+1)\n",
    "plt.plot(epochs, train_loss_list, 'ro', label=\"training loss\")\n",
    "plt.plot(epochs, val_loss_list, 'r', label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8drM4GegxFP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSVyWlKpg2-z"
   },
   "source": [
    "## Test ACC\n",
    "**100 epochs, SGD**\n",
    "* Pure model (Res14): 71.17%\n",
    "* Res20: 67.41%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/logs/SGD2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hyk5b1MhA7W"
   },
   "outputs": [],
   "source": [
    "def plot_acc():\n",
    "    epochs = range(1, self.epochs+1)\n",
    "    plt.plot(epochs, self.train_acc_list, 'bo', label=\"Training acc\")\n",
    "    plt.plot(epochs, self.val_acc_list, 'b', label=\"Validation acc\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss():\n",
    "    epochs = range(1, self.epochs+1)\n",
    "    plt.plot(epochs, self.train_loss_list, 'ro', label=\"Training loss\")\n",
    "    plt.plot(epochs, self.val_loss_list, 'r', label=\"Validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
